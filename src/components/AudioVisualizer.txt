import { useEffect, useRef } from "react";

interface AudioVisualizerProps {
    audio: HTMLAudioElement;
}

const AudioVisualizer = ({ audio }: AudioVisualizerProps) => {
  const [analyser, setAnalyser] = useState<AnalyserNode>();
  const [context, setContext] = useState<AudioContext>();
  const [audioSource, setAudioSource] = useState<MediaElementAudioSourceNode>();
    const canvasRef = useRef(null);
  
    useEffect(() => {
      if (!audioContextRef.current) {
        audioContextRef.current = new AudioContext();
      }
  
      const audioContext = audioContextRef.current;
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;
      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);
  
      analyserRef.current = analyser;
      dataArrayRef.current = dataArray;
  
      const source = audioContext.createMediaElementSource(audio);
      source.connect(analyser);
      analyser.connect(audioContext.destination);
  
      const canvas = canvasRef.current;
      const canvasCtx = canvas.getContext('2d');
  
      const draw = () => {
        requestAnimationFrame(draw);
  
        analyser.getByteFrequencyData(dataArray);
  
        canvasCtx.fillStyle = 'rgb(0, 0, 0)';
        canvasCtx.fillRect(0, 0, canvas.width, canvas.height);
  
        const barWidth = (canvas.width / bufferLength) * 2.5;
        let barHeight;
        let x = 0;
  
        for (let i = 0; i < bufferLength; i++) {
          barHeight = dataArray[i];
  
          canvasCtx.fillStyle = 'rgb(' + (barHeight + 100) + ',50,50)';
          canvasCtx.fillRect(x, canvas.height - barHeight / 2, barWidth, barHeight / 2);
  
          x += barWidth + 1;
        }
      };
  
      draw();
    }, [audio]);
  
    return <canvas ref={canvasRef} width="640" height="100" style={{ position: 'absolute', zIndex: 1 }} />;
  };

export default AudioVisualizer;